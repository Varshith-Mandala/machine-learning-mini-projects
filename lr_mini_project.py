# -*- coding: utf-8 -*-
"""LR_Mini_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NsbW0DMIUPYF8ud_q5oADYvdM1LzKDOA
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

data_set=np.array([[210000,180000,950,2,1],
[245000,200000,1100,3,1],
[275000,225000,1300,3,2],
[310000,260000,1550,4,2],
[195000,165000,900,2,1],
[340000,290000,1750,4,2],
[365000,315000,1950,5,2],
[390000,340000,2150,5,3],
[425000,370000,2400,6,3],
[460000,400000,2650,6,3],
[230000,190000,1000,3,1],
[255000,215000,1200,3,2],
[285000,240000,1400,4,2],
[315000,270000,1600,4,2],
[350000,300000,1850,5,2],
[380000,330000,2050,5,3],
[410000,360000,2300,6,3],
[445000,390000,2550,6,3],
[480000,420000,2800,7,3],
[505000,450000,3050,7,4],
[225000,185000,980,2,1],
[265000,220000,1250,3,2],
[305000,255000,1500,4,2],
[355000,305000,1900,5,2],
[430000,365000,2450,6,3]
])
x_features=["Price","Area","Rooms","Floors"]

X=data_set[:,1:]
Y=data_set[:,0]
def split_data(X,Y):
    x_tr = X[:int(0.6*len(X))]
    x_v = X[int(0.6*len(X)):int(0.8*len(X))]
    x_t  = X[int(0.8*len(X)):]
    y_tr = Y[:int(0.6*len(Y))]
    y_v = Y[int(0.6*len(Y)):int(0.8*len(Y))]
    y_t  = Y[int(0.8*len(Y)):]
    return x_tr,x_v,x_t,y_tr,y_v,y_t
x_train,x_val,x_test,y_train,y_val,y_test=split_data(X,Y)

fig,ax=plt.subplots(1, 4, figsize=(12, 3), sharey=True)
for i in range(len(ax)):
    ax[i].scatter(x_train[:,i],y_train,marker='x',c='r')
    ax[i].set_xlabel(x_features[i])
ax[0].set_ylabel("Price (1000's)")
plt.show()

def normalize(x,denormalize=False):
  mean=np.mean(x,axis=0)
  std=np.std(x,axis=0)
  x_norm=(x-mean)/std
  return x_norm,std,mean
x_train_norm,std,mean=normalize(x_train)

w_init=np.zeros(4)
b_init=0
def gradient_descent(x,y,w,b,lrate,iterations):
  m=x.shape[0]
  for _ in range(iterations):
    f_wb=np.dot(x,w)+b

    dw=(1/m)*np.dot(x.T,(f_wb-y))
    db=(1/m)*np.sum(f_wb-y)

    w-=(lrate*dw)
    b-=(lrate*db)

  return w,b
w_init,b_init=gradient_descent(x_train_norm,y_train,w_init,b_init,0.01,1000)

def Lin_Reg(x,w,b):
  return np.dot(x,w)+b
y_pred=Lin_Reg(x_train_norm,w_init,b_init)

plt.scatter(y_train, y_pred,marker='x',c='r')
plt.xlabel("Actual Price")
plt.ylabel("Predicted Price")
plt.plot([y_train.min(), y_train.max()],
         [y_train.min(), y_train.max()])
plt.title("Predicted vs Actual")
plt.show()

fg,ar=plt.subplots(1,4,figsize=(12,3))
for i in range(len(ar)):
  ar[i].scatter(x_train[:,i],y_train,c='r',label="Original")
  ar[i].scatter(x_train[:,i],y_pred,c='b',label="Predicted")
  ar[i].set_xlabel(x_features[i])
  ar[i].legend()
plt.tight_layout()
plt.show()

